{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_02_T_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamSaw/deep-unsupervised-learning/blob/HW_02_T_02/HW_02_T_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6yilnNbWC0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "from torch.distributions import Normal, MultivariateNormal, Uniform\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAgXxgm-Zjcx",
        "colab_type": "code",
        "outputId": "2cc7337c-663c-477f-edbd-16c8605bd00b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def make_reproducible(seed, make_cuda_reproducible):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if make_cuda_reproducible:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "SEED = 2341\n",
        "make_reproducible(SEED, False)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_QS-QUXZkwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('hw2_q2.pkl', 'rb') as f:\n",
        "    DATA = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvGb5Y2fZvwz",
        "colab_type": "code",
        "outputId": "4b71dea6-c2ac-46c0-fe6e-c4091e0e128f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(DATA.keys())\n",
        "print(DATA['train'].shape)\n",
        "print(DATA['test'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['train', 'test'])\n",
            "(20000, 32, 32, 3)\n",
            "(6838, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_SEZLjkZ0c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show(img): \n",
        "    plt.imshow(img / 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDtnEbCZ043",
        "colab_type": "code",
        "outputId": "12eb31cf-6559-4a10-bc94-fb560cda47c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "show(DATA['train'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rRVE-3IZ2ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self, ch_in, n_filters=256, n_blocks=8):\n",
        "        super(Resnet,self).__init__()\n",
        "        ch_out = ch_in * 2\n",
        "        self.n_blocks = n_blocks\n",
        "        self.conv1 = nn.Conv2d(ch_in, n_filters, kernel_size=(3, 3), stride=(1, 1), padding=2)\n",
        "        get_ht_model = lambda: nn.Sequential(\n",
        "            nn.Conv2d(n_filters, n_filters, kernel_size=(1, 1), stride=(1, 1), padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n_filters, n_filters, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
        "        )\n",
        "        get_h_model = lambda: nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n_filters, n_filters, kernel_size=(1,1), stride=(1, 1), padding=0)\n",
        "        )\n",
        "        self._h_model = torch.nn.ModuleList([get_ht_model() for _ in range(n_blocks)])\n",
        "        self.h_model = torch.nn.ModuleList([get_h_model() for _ in range(n_blocks)])\n",
        "        #self.h_sum = torch.nn.ModuleList([nn.ReLU() for _ in range(n_blocks)])\n",
        "        self.conv2 = nn.Conv2d(n_filters, ch_out, kernel_size=(3, 3), stride=(1, 1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x)\n",
        "        for i in range(self.n_blocks):\n",
        "            _h = self._h_model[i](h)\n",
        "            h = self.h_model[i](_h)\n",
        "            h = (h + _h)\n",
        "        h = F.relu(h)\n",
        "        x = self.conv2(h)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz6brm8AcZwU",
        "colab_type": "code",
        "outputId": "5f6c3a89-1377-4ed5-cb7b-731795a23045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Resnet(3, 2)(torch.randn((64, 3, 32, 32))).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 6, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMjLXWP9cYkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AffineCoupling(nn.Module):\n",
        "    def __init__(self, ch_in):\n",
        "        super(AffineCoupling, self).__init__()\n",
        "        self.resnet = Resnet(ch_in)\n",
        "    def forward(self, x):\n",
        "      (x1, x2) = x\n",
        "      y1 = x1\n",
        "      log_s, t = torch.chunk(self.resnet(x1), 2, dim=1)\n",
        "      y2 = torch.exp(log_s) * (y1 + t)\n",
        "      log_det = log_s.view(x1.shape[0], -1).sum(dim=1)\n",
        "      return ((y1, y2), log_det)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCjlhiS3p1OD",
        "colab_type": "code",
        "outputId": "e841928f-35b9-458f-db79-0611d2266f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "for out in AffineCoupling(3)((torch.randn((5, 3, 32, 32)), torch.randn((5, 3, 32, 32))))[0]:\n",
        "  print(out.shape)\n",
        "AffineCoupling(3)((torch.randn((5, 3, 32, 32)), torch.randn((5, 3, 32, 32))))[1].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 32, 32])\n",
            "torch.Size([5, 3, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvDmdAJEq5Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CelebA(nn.Module):\n",
        "  def __init__(self, ch_in):\n",
        "      super(CelebA, self).__init__()\n",
        "      self.prior = Normal(torch.tensor(0.).to(DEVICE), torch.tensor(1.).to(DEVICE))\n",
        "      self.couplings1 = torch.nn.ModuleList([AffineCoupling(ch_in) for _ in range(4)])\n",
        "      self.couplings2 = torch.nn.ModuleList([AffineCoupling(ch_in * 2) for _ in range(3)])\n",
        "      self.couplings3 = torch.nn.ModuleList([AffineCoupling(ch_in * 4) for _ in range(3)])\n",
        "      self.couplings4 = torch.nn.ModuleList([AffineCoupling(ch_in * 8) for _ in range(3)])\n",
        "      self.couplings5 = torch.nn.ModuleList([AffineCoupling(ch_in * 16) for _ in range(3)])\n",
        "\n",
        "  def build_mask(self, size, config=1.):\n",
        "      mask = np.arange(size).reshape(-1, 1) + np.arange(size)\n",
        "      mask = np.mod(config + mask, 2)\n",
        "      mask = mask.reshape(-1, 1, size, size)\n",
        "      return torch.tensor(mask.astype('float32'))\n",
        "\n",
        "  def flip_tuple(self, x):\n",
        "      (x1, x2) = x\n",
        "      return (x2, x1)\n",
        "\n",
        "  def checkerboard_split(self, x):\n",
        "      mask = self.build_mask(x.shape[2], config=0.).to(DEVICE)\n",
        "      return (x * mask, x * (1 - mask)) # TODO: is it correct split?\n",
        "\n",
        "  def inverse_checkerboard_split(self, x):\n",
        "      return x[0] + x[1] # TODO: is it correct split?\n",
        "\n",
        "  def squeeze(self, x):\n",
        "      x = x.permute(0, 2, 3, 1)\n",
        "      x = x.reshape(-1, x.shape[1] // 2, x.shape[2] // 2, 4 * x.shape[3])\n",
        "      x = x.permute(0, 3, 1, 2)\n",
        "      return x\n",
        "\n",
        "  def channel_split(self, x):\n",
        "      return torch.chunk(x, 2, dim=1)\n",
        "\n",
        "  def inverse_channel_split(self, x):\n",
        "      return torch.cat([x[0], x[1]], dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "      log_det = 0\n",
        "\n",
        "      x = self.checkerboard_split(x) \n",
        "      for i in range(4):\n",
        "          x, log_det_temp = self.couplings1[i](x)\n",
        "          log_det += log_det_temp\n",
        "          x = self.flip_tuple(x)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "      \n",
        "      x = self.squeeze(x)\n",
        "      \n",
        "      x = self.channel_split(x)\n",
        "      for i in range(3):\n",
        "          x, log_det_temp = self.couplings2[i](x)\n",
        "          log_det += log_det_temp\n",
        "          x = self.flip_tuple(x)\n",
        "      x = self.inverse_channel_split(x)\n",
        "\n",
        "      x = self.checkerboard_split(x)\n",
        "      for i in range(3):\n",
        "          x, log_det_temp = self.couplings3[i](x)\n",
        "          log_det += log_det_temp\n",
        "          x = self.flip_tuple(x)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "      \n",
        "      x = self.squeeze(x)\n",
        "      \n",
        "      x = self.channel_split(x)\n",
        "      for i in range(3):\n",
        "          x, log_det_temp = self.couplings4[i](x)\n",
        "          log_det += log_det_temp\n",
        "          x = self.flip_tuple(x)\n",
        "      x = self.inverse_channel_split(x)\n",
        "\n",
        "      x = self.checkerboard_split(x)\n",
        "      for i in range(3):\n",
        "          x, log_det_temp = self.couplings5[i](x)\n",
        "          log_det += log_det_temp\n",
        "          x = self.flip_tuple(x)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "\n",
        "      return x, log_det\n",
        "    \n",
        "  def log_prob(self, x):\n",
        "      z, log_det_J = self.forward(x)\n",
        "      log_prior_prob = torch.sum(self.prior.log_prob(z), dim=(1, 2, 3))\n",
        "      return log_prior_prob + log_det_J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxqVP0YuvjZR",
        "colab_type": "code",
        "outputId": "6a27f98e-5048-495b-adfb-d492fe0171c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "CelebA(3).to(DEVICE).log_prob(torch.randn((5, 3, 32, 32)).to(DEVICE))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-13554.7695, -14249.4619, -15598.8584, -16091.0342, -15630.9756],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp7r-_P8v2FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "TRAIN_DATALOADER = DataLoader(DATA['train'], batch_size=BATCH_SIZE, shuffle=True)\n",
        "TEST_DATALOADER = DataLoader(DATA['test'], batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-cs1jwVAqh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL = CelebA(3).to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71PK-B_5BdVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZezxH4fBGag",
        "colab_type": "code",
        "outputId": "2d171589-8d25-4f98-dee4-17b40a96b050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "count_parameters(MODEL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-3dff5db427da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMK54KscBISi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}