{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW_02_T_02(2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74cc05657c3044a59e4718a3b0a41f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a634e8016a5a4e14a151c74cff07e0fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8662d094b4d843529fc35a67e198226e",
              "IPY_MODEL_9fc47c8e7e0b48b6a9561196264ef358"
            ]
          }
        },
        "a634e8016a5a4e14a151c74cff07e0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8662d094b4d843529fc35a67e198226e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4401ef235e15496193648489b8b4facb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b16a4b8b3314c9bb3256711a47cb51a"
          }
        },
        "9fc47c8e7e0b48b6a9561196264ef358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7eb50c6224f40b8bde441dd789fd524",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 10/10 [00:08&lt;00:00,  1.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a2bcce880124bdeb11436ca898eca7e"
          }
        },
        "4401ef235e15496193648489b8b4facb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b16a4b8b3314c9bb3256711a47cb51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7eb50c6224f40b8bde441dd789fd524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a2bcce880124bdeb11436ca898eca7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c2298d9e3ed44a8a2335da7b21ab605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ece695d52f54c5aa9986521f65a5cc9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc1696f3070243edafe6239a162d4fda",
              "IPY_MODEL_1fd26749362f48269040b3eecfa3ed4b"
            ]
          }
        },
        "6ece695d52f54c5aa9986521f65a5cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc1696f3070243edafe6239a162d4fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e66b8ff51c341c4830ec1c279b38293",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_901e34e2103b4f69bea24f8446d2a33b"
          }
        },
        "1fd26749362f48269040b3eecfa3ed4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_30a2101cc30e44ab893dc10c92100634",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30% 3/10 [00:02&lt;00:06,  1.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a34907ab1b7c44e7b8e230a8abc13235"
          }
        },
        "3e66b8ff51c341c4830ec1c279b38293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "901e34e2103b4f69bea24f8446d2a33b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30a2101cc30e44ab893dc10c92100634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a34907ab1b7c44e7b8e230a8abc13235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamSaw/deep-unsupervised-learning/blob/HW_02_T_02/HW_02_T_02(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l6yilnNbWC0j",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "from torch.distributions import Normal, MultivariateNormal, Uniform\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KAgXxgm-Zjcx",
        "outputId": "ed4b00cc-9854-451b-ee6c-a36739ad5438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def make_reproducible(seed, make_cuda_reproducible):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if make_cuda_reproducible:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "SEED = 2341\n",
        "make_reproducible(SEED, False)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IvGb5Y2fZvwz",
        "outputId": "882985f6-e046-4955-b51e-22d2fe820981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "with open('hw2_q2.pkl', 'rb') as f:\n",
        "    DATA = pickle.load(f)\n",
        "print(DATA.keys())\n",
        "DATA['train'] = torch.FloatTensor(DATA['train']).permute(0, 3, 1, 2)\n",
        "DATA['test'] = torch.FloatTensor(DATA['test']).permute(0, 3, 1, 2)\n",
        "print(DATA['train'].shape)\n",
        "print(DATA['test'].shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['train', 'test'])\n",
            "torch.Size([20000, 3, 32, 32])\n",
            "torch.Size([6838, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w_SEZLjkZ0c-",
        "colab": {}
      },
      "source": [
        "def show(images):\n",
        "    images = images.permute(0, 2, 3, 1)\n",
        "    fig=plt.figure(figsize=(8, 8))\n",
        "    columns = images.shape[0]\n",
        "    rows = 1\n",
        "    for i, img in enumerate(images):\n",
        "        fig.add_subplot(rows, columns, i + 1)\n",
        "        plt.imshow(img / 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "orDtnEbCZ043",
        "outputId": "8bee9f38-19e5-49c4-be96-bd896d0ef3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "show(DATA['train'][:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAABvCAYAAAA0RRMsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8rRVE-3IZ2ue",
        "colab": {}
      },
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self, ch_in, n_filters=256, n_blocks=8):\n",
        "        super(Resnet,self).__init__()\n",
        "        ch_out = ch_in * 2\n",
        "        self.n_blocks = n_blocks\n",
        "        self.conv1 = nn.Conv2d(ch_in, n_filters, kernel_size=(3, 3), stride=(1, 1), padding=2)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(n_filters)\n",
        "        get_ht_model = lambda: nn.Sequential(\n",
        "            nn.Conv2d(n_filters, n_filters, kernel_size=(1, 1), stride=(1, 1), padding=0),\n",
        "            nn.BatchNorm2d(n_filters),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n_filters, n_filters, kernel_size=(3, 3), stride=(1, 1), padding=1),\n",
        "            nn.BatchNorm2d(n_filters)\n",
        "        )\n",
        "        get_h_model = lambda: nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n_filters, n_filters, kernel_size=(1,1), stride=(1, 1), padding=0),\n",
        "            nn.BatchNorm2d(n_filters)\n",
        "        )\n",
        "        self._h_model = torch.nn.ModuleList([get_ht_model() for _ in range(n_blocks)])\n",
        "        self.h_model = torch.nn.ModuleList([get_h_model() for _ in range(n_blocks)])\n",
        "        #self.h_sum = torch.nn.ModuleList([nn.ReLU() for _ in range(n_blocks)])\n",
        "        self.conv2 = nn.Conv2d(n_filters, ch_out, kernel_size=(3, 3), stride=(1, 1))\n",
        "        self.batch_norm2 = nn.BatchNorm2d(ch_out)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x)\n",
        "        h = self.batch_norm1(h)\n",
        "        for i in range(self.n_blocks):\n",
        "            _h = self._h_model[i](h)\n",
        "            h = self.h_model[i](_h)\n",
        "            h = (h + _h)\n",
        "        h = F.relu(h)\n",
        "        x = self.conv2(h)\n",
        "        x = self.batch_norm2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zz6brm8AcZwU",
        "outputId": "f9e1d408-1ca3-4749-93ac-5ae295a75ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Resnet(3, 2)(torch.randn((64, 3, 32, 32))).shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 6, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sMjLXWP9cYkC",
        "colab": {}
      },
      "source": [
        "class AffineCoupling(nn.Module):\n",
        "    def __init__(self, ch_in, sign):\n",
        "        super(AffineCoupling, self).__init__()\n",
        "        self.resnet = Resnet(ch_in)\n",
        "        self.sign = sign\n",
        "    \n",
        "    def forward(self, x, masks):\n",
        "        (x1, x2) = x\n",
        "        y1 = x1\n",
        "        log_s, t = torch.chunk(self.resnet(x1), 2, dim=1)\n",
        "        y2 = torch.exp(log_s) * (x2 + t * masks[1]) # TODO: y1 or x2?\n",
        "        log_det = log_s.view(x1.shape[0], -1).sum(dim=1) * self.sign\n",
        "        return ((y1, y2), log_det)\n",
        "\n",
        "    def reverse(self, y, mask):\n",
        "        (y1, y2) = y\n",
        "        x1 = y1\n",
        "        log_s, t = torch.chunk(self.resnet(x1), 2, dim=1)\n",
        "        x2 = y2 * torch.exp(-log_s) - t * (1 - mask[1])\n",
        "        return (x1, x2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BCjlhiS3p1OD",
        "outputId": "3bc6d4b9-9135-463d-b5a5-b0ca70acbec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "for out in AffineCoupling(3, 1.0)((torch.randn((5, 3, 32, 32)), torch.randn((5, 3, 32, 32))), (torch.ones((5, 3, 32, 32)), torch.ones((5, 3, 32, 32))))[0]:\n",
        "    print(out.shape)\n",
        "print(AffineCoupling(3, -1.0)((torch.randn((5, 3, 32, 32)), torch.randn((5, 3, 32, 32))), (torch.ones((5, 3, 32, 32)), torch.ones((5, 3, 32, 32))))[1].shape)\n",
        "for out in AffineCoupling(3, -1.0).reverse((torch.randn((5, 3, 32, 32)), torch.randn((5, 3, 32, 32))), (torch.ones((5, 3, 32, 32)), torch.ones((5, 3, 32, 32)))):\n",
        "    print(out.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 32, 32])\n",
            "torch.Size([5, 3, 32, 32])\n",
            "torch.Size([5])\n",
            "torch.Size([5, 3, 32, 32])\n",
            "torch.Size([5, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xvDmdAJEq5Ka",
        "colab": {}
      },
      "source": [
        "class CelebA(nn.Module):\n",
        "  def __init__(self, ch_in):\n",
        "      super(CelebA, self).__init__()\n",
        "      self.prior = Normal(torch.tensor(0.).to(DEVICE), torch.tensor(1.).to(DEVICE))\n",
        "      signs = [1, 1, 1, 1] # TODO: maybe log_det_J after tuple flip must change signs?\n",
        "      self.couplings1 = torch.nn.ModuleList([AffineCoupling(ch_in, signs[i]) for i in range(4)])\n",
        "      self.couplings2 = torch.nn.ModuleList([AffineCoupling(ch_in * 4, signs[i]) for i in range(3)])\n",
        "      self.couplings3 = torch.nn.ModuleList([AffineCoupling(ch_in * 4, signs[i]) for i in range(3)])\n",
        "      self.couplings4 = torch.nn.ModuleList([AffineCoupling(ch_in * 16, signs[i]) for i in range(3)])\n",
        "      self.couplings5 = torch.nn.ModuleList([AffineCoupling(ch_in * 16, signs[i]) for i in range(3)])\n",
        "\n",
        "  def build_mask(self, size, config=1.):\n",
        "      mask = np.arange(size).reshape(-1, 1) + np.arange(size)\n",
        "      mask = np.mod(config + mask, 2)\n",
        "      mask = mask.reshape(-1, 1, size, size)\n",
        "      return torch.tensor(mask.astype('float32'))\n",
        "\n",
        "  def flip_tuple(self, x, masks):\n",
        "      (x1, x2) = x\n",
        "      (mask1, mask2) = masks\n",
        "      return (x2, x1), (mask2, mask1)\n",
        "\n",
        "  def checkerboard_split(self, x):\n",
        "      mask = self.build_mask(x.shape[2], config=1.).to(DEVICE)\n",
        "      return (x * mask, x * (1 - mask)), (mask, 1 - mask) # TODO: is it correct split?\n",
        "\n",
        "  def inverse_checkerboard_split(self, x):\n",
        "      return x[0] + x[1] # TODO: is it correct split?\n",
        "\n",
        "  def squeeze(self, x):\n",
        "      x = x.reshape(-1, 4 * x.shape[1], x.shape[2] // 2, x.shape[3] // 2)\n",
        "      return x\n",
        "  \n",
        "  def unsqueeze(self, x):\n",
        "      #x = x.permute(0, 2, 3, 1)\n",
        "      #x = x.reshape(-1, x.shape[1] * 2, x.shape[2] * 2, x.shape[3] // 4)\n",
        "      #x = x.permute(0, 3, 1, 2)\n",
        "      x = x.reshape(-1, x.shape[1] // 4, x.shape[2] * 2, x.shape[3] * 2)\n",
        "      return x\n",
        "\n",
        "  \n",
        "  def channel_split(self, x):\n",
        "      mask = torch.zeros((1, x.shape[1], x.shape[2], x.shape[3])).to(DEVICE)\n",
        "      mask[:, :mask.shape[1] // 2, :, :] = 1\n",
        "      return (x * mask, x * (1 - mask)), (mask, 1 - mask)\n",
        "\n",
        "  def inverse_channel_split(self, x):\n",
        "      return x[0] + x[1]\n",
        "\n",
        "  def forward(self, x):\n",
        "      log_det = 0\n",
        "\n",
        "      x, masks = self.checkerboard_split(x) \n",
        "      for i in range(4):\n",
        "          x, log_det_temp = self.couplings1[i](x, masks)\n",
        "          log_det += log_det_temp\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "      \n",
        "      x = self.squeeze(x)\n",
        "      \n",
        "      x, masks = self.channel_split(x)\n",
        "      for i in range(3):\n",
        "          x, log_det_temp = self.couplings2[i](x, masks)\n",
        "          log_det += log_det_temp\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "      x = self.inverse_channel_split(x)\n",
        "\n",
        "      x, masks = self.checkerboard_split(x)\n",
        "      for i in range(3):\n",
        "          x, log_det_temp = self.couplings3[i](x, masks)\n",
        "          log_det += log_det_temp\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "      \n",
        "      x = self.squeeze(x)\n",
        "      \n",
        "      x, masks = self.channel_split(x)\n",
        "      for i in range(3):\n",
        "          x, log_det_temp = self.couplings4[i](x, masks)\n",
        "          log_det += log_det_temp\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "      x = self.inverse_channel_split(x)\n",
        "\n",
        "      x, masks = self.checkerboard_split(x)\n",
        "      for i in range(3):\n",
        "          x, log_det_temp = self.couplings5[i](x, masks)\n",
        "          log_det += log_det_temp\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "\n",
        "      #x = self.unsqueeze(self.unsqueeze(x)) # TODO: Is it correct to do so?\n",
        "\n",
        "      return x, log_det\n",
        "    \n",
        "  def reverse(self, z):\n",
        "      x = z\n",
        "      #x = self.squeeze(self.squeeze(x))\n",
        "      \n",
        "      x, masks = self.checkerboard_split(x)\n",
        "      for i in range(3):\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "          x = self.couplings5[i].reverse(x, masks)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "\n",
        "      x, masks = self.channel_split(x)\n",
        "      for i in range(3):\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "          x = self.couplings4[i].reverse(x, masks)\n",
        "      x = self.inverse_channel_split(x)\n",
        "\n",
        "      x = self.unsqueeze(x)\n",
        "\n",
        "      x, masks = self.checkerboard_split(x)\n",
        "      for i in range(3):\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "          x = self.couplings3[i].reverse(x, masks)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "\n",
        "      x, masks = self.channel_split(x)\n",
        "      for i in range(3):\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "          x = self.couplings2[i].reverse(x, masks)\n",
        "      x = self.inverse_channel_split(x)\n",
        "      \n",
        "      x = self.unsqueeze(x)\n",
        "      \n",
        "      x, masks = self.checkerboard_split(x) \n",
        "      for i in range(4):\n",
        "          x, masks = self.flip_tuple(x, masks)\n",
        "          x = self.couplings1[i].reverse(x, masks)\n",
        "      x = self.inverse_checkerboard_split(x)\n",
        "\n",
        "      return x\n",
        "    \n",
        "  def log_prob(self, x):\n",
        "      z, log_det_J = self.forward(x)\n",
        "      log_prior_prob = torch.sum(self.prior.log_prob(z), dim=(1, 2, 3))\n",
        "      return log_prior_prob + log_det_J\n",
        "  \n",
        "  def sample(self, size):\n",
        "        #z = self.prior.sample((size, 3, 32, 32))\n",
        "        z = self.prior.sample((size, 48, 8, 8))\n",
        "        return self.reverse(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dxqVP0YuvjZR",
        "outputId": "b6b251d5-765d-4185-9a07-2a197db27284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(CelebA(3).to(DEVICE)(torch.randn((5, 3, 32, 32)).to(DEVICE))[0].shape)\n",
        "print(CelebA(3).to(DEVICE)(torch.randn((5, 3, 32, 32)).to(DEVICE))[1].shape)\n",
        "print(CelebA(3).to(DEVICE)(torch.randn((5, 3, 32, 32)).to(DEVICE))[1])\n",
        "print(CelebA(3).to(DEVICE).log_prob(torch.randn((5, 3, 32, 32)).to(DEVICE)))\n",
        "print(CelebA(3).to(DEVICE).sample(3).shape)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 48, 8, 8])\n",
            "torch.Size([5])\n",
            "tensor([  13.0618,  -51.3120,   22.7720, -335.9862,  351.4636],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor([-3.9256e+05, -4.9611e+27, -1.3252e+07, -6.0869e+04, -3.6197e+04],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "torch.Size([3, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "71PK-B_5BdVv",
        "colab": {}
      },
      "source": [
        "def count_parameters():\n",
        "    model = CelebA(3)\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jZezxH4fBGag",
        "outputId": "c18d2538-44c8-4e5a-932d-fed2d49e1e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count_parameters()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95155384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QHXpd4aIuxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_batch_size, test_batch_size, epochs_cnt, train_data=DATA['train'], test_data=DATA['test'], lr=5e-5):\n",
        "    dim_factor = torch.FloatTensor([3 * 32 * 32]).to(DEVICE)\n",
        "    log_factor = torch.log(torch.Tensor([2])).to(DEVICE)\n",
        "        \n",
        "    def loss_func(log_prob):\n",
        "        return -torch.mean(log_prob) / dim_factor / log_factor\n",
        "    \n",
        "    train_iter = DataLoader(train_data, batch_size=train_batch_size, shuffle=True)\n",
        "    val_iter = DataLoader(test_data, batch_size=test_batch_size, shuffle=False)\n",
        "    optimizer = torch.optim.Adam(MODEL.parameters(),lr=lr, weight_decay=0.0001)\n",
        "\n",
        "    losses, val_losses = [], []\n",
        "    for epoch in range(epochs_cnt):\n",
        "        loss = 0\n",
        "        tmp_losses = []\n",
        "        \n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for batch in tqdm(train_iter):\n",
        "            batch = batch.to(DEVICE)\n",
        "            loss = loss_func(model.log_prob(batch))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            tmp_losses.append(loss.data.cpu().numpy())\n",
        "        losses.append(np.mean(tmp_losses))\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            tmp_val_losses = []\n",
        "            for item in val_iter:\n",
        "                batch = batch.to(DEVICE)\n",
        "                val_loss = loss_func(model.log_prob(batch))\n",
        "                tmp_val_losses.append(val_loss.data.cpu().numpy())\n",
        "            val_losses.append(np.mean(tmp_val_losses))\n",
        "        if epoch % 1 ==0:\n",
        "            print('Epoch {}: loss {} val_loss {} '.format(epoch, np.mean(tmp_losses), np.mean(tmp_val_losses)))\n",
        "    return losses, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKcVVV8TIuxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_losses(losses, val_losses):\n",
        "    plt.plot(losses, label = \"train_loss\")\n",
        "    plt.plot(val_losses, label = \"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt-yYlb9Iuxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE = 16\n",
        "TEST_BATCH_SIZE = 16\n",
        "EPOCHS_CNT = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWYNqaekLdRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL = CelebA(3).to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRAk-rcpIux4",
        "colab_type": "code",
        "outputId": "8b199774-4aa3-4e87-93f8-9c3f10f748c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446,
          "referenced_widgets": [
            "74cc05657c3044a59e4718a3b0a41f5c",
            "a634e8016a5a4e14a151c74cff07e0fa",
            "8662d094b4d843529fc35a67e198226e",
            "9fc47c8e7e0b48b6a9561196264ef358",
            "4401ef235e15496193648489b8b4facb",
            "0b16a4b8b3314c9bb3256711a47cb51a",
            "b7eb50c6224f40b8bde441dd789fd524",
            "1a2bcce880124bdeb11436ca898eca7e",
            "7c2298d9e3ed44a8a2335da7b21ab605",
            "6ece695d52f54c5aa9986521f65a5cc9",
            "fc1696f3070243edafe6239a162d4fda",
            "1fd26749362f48269040b3eecfa3ed4b",
            "3e66b8ff51c341c4830ec1c279b38293",
            "901e34e2103b4f69bea24f8446d2a33b",
            "30a2101cc30e44ab893dc10c92100634",
            "a34907ab1b7c44e7b8e230a8abc13235"
          ]
        }
      },
      "source": [
        "TRAIN_LOSSES, VAL_LOSSES = train(MODEL, TRAIN_BATCH_SIZE, TEST_BATCH_SIZE, EPOCHS_CNT, train_data=DATA['train'][:160], test_data=DATA['test'][:32])\n",
        "plot_losses(TRAIN_LOSSES, VAL_LOSSES)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74cc05657c3044a59e4718a3b0a41f5c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0: loss nan val_loss nan \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c2298d9e3ed44a8a2335da7b21ab605",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-82c4be9c6f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTRAIN_LOSSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVAL_LOSSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_BATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_BATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_CNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_LOSSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVAL_LOSSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-805a0047794d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_batch_size, test_batch_size, epochs_cnt, train_data, test_data, lr)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSeqi_RZIuyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}